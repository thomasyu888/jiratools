{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JIRA metrics\n",
    "This is a juypter notebook to walk through the steps required to pull down Jira sprint metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are your imports\n",
    "import os\n",
    "\n",
    "from jira import JIRA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure JIRA python client and login with your\n",
    "# API token\n",
    "username = os.environ['JIRA_USERNAME']\n",
    "api_token = os.environ['JIRA_API_TOKEN']\n",
    "jira_client = JIRA(\n",
    "    server='https://sagebionetworks.jira.com/',\n",
    "    basic_auth=(username, api_token)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPE 11.07.22 - 11.18.22\n",
      "Orca 11.21.22 - 12.05.22\n",
      "Orca 11.07.22 - 11.18.22\n",
      "ETL 11.07.22 - 11.18.23\n",
      "ETL 11.21.22 - 12.05.22\n",
      "DPE 11.21.22 - 12.05.22\n",
      "Orca 12.05.22 - 12.16.22\n",
      "ETL 12.05.22 - 12.19.22\n",
      "DPE 12.05.22 - 12.16.22\n",
      "DPE 12.19.22 - 01.02.23\n",
      "Orca 12.19.22 - 01.02.23\n",
      "ETL 12.19.22 - 01.02.23\n",
      "DPE 01.03.23 - 01.16.23\n",
      "ETL 01.03.23 - 01.16.23\n",
      "ETL 2023-01-17 to 2023-01-29\n",
      "DPE 2023-01-17 to 2023-01-29\n",
      "DPE 2023-01-30 to 2023-02-13\n",
      "ETL 2023-01-30 to 2023-02-13\n",
      "DPE 2023-02-13 to 2023-02-27\n",
      "ETL 2023-02-13 to 2023-02-27\n",
      "DPE 2023-02-27 to 2023-03-13\n",
      "ETL 2023-02-27 to 2023-03-13\n",
      "DPE 2023-03-13 to 2023-03-27\n",
      "Orca 2023-03-13 to 2023-03-27\n",
      "ETL 2023-03-13 to 2023-03-27\n",
      "DPE 2023-03-27 to 2023-04-10\n"
     ]
    }
   ],
   "source": [
    "# Get all sprints\n",
    "# Board 189 is the DPE scrum board\n",
    "all_sprints = jira_client.sprints(board_id=189)\n",
    "for sprint in all_sprints:\n",
    "    if sprint.name.startswith((\"ETL\", \"Orca\", \"DPE\")) and \"Sprint\" not in sprint.name:\n",
    "        print(sprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tickets for a specific sprint\n",
    "sprint_id = sprint.id\n",
    "issues = jira_client.search_issues(f\"sprint={sprint_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all issues in a sprint\n",
    "# This does NOT take into account the specific status of\n",
    "# an issue at the duration of the sprint\n",
    "# For example, an issue could be \"Waiting for review\" at the\n",
    "# end of the sprint, but can be \"Closed\" now. This will\n",
    "# skew the \"number of story points\" per engineer over time.\n",
    "result = []\n",
    "for issue in issues:\n",
    "    issue_info = jira_client.issue(issue.id)\n",
    "    issue_assignee = issue_info.fields.assignee.displayName\n",
    "    # Story points\n",
    "    issue_story_points = issue_info.fields.customfield_10014\n",
    "    # Status of ticket\n",
    "    issue_status = issue_info.fields.status.name\n",
    "    issue_summary = issue_info.fields.summary\n",
    "    issue_desc = issue_info.fields.description\n",
    "    issue_type_name = issue_info.fields.issuetype.name\n",
    "    # Target start\n",
    "    issue_start_date = issue_info.fields.customfield_12113\n",
    "    issue_due_date = issue_info.fields.duedate\n",
    "\n",
    "    result.append({\n",
    "        'sprint_id': sprint_id,\n",
    "        \"issuetype\": issue_type_name,\n",
    "        \"key\": issue.id,\n",
    "        \"summary\": issue_summary,\n",
    "        \"description\": issue_desc,\n",
    "        'status': issue_status,\n",
    "        \"assignee\": issue_assignee,\n",
    "        \"sprint\": sprint,\n",
    "        \"target_start\": issue_start_date,\n",
    "        \"due_date\": issue_due_date\n",
    "    })\n",
    "jira_issues_df = pd.DataFrame(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sprint_id issuetype    key  \\\n",
      "0         573       Bug  84823   \n",
      "1         573     Story  85844   \n",
      "2         573     Story  85843   \n",
      "3         573     Story  85841   \n",
      "4         573     Story  85128   \n",
      "5         573     Story  84711   \n",
      "6         573     Story  84631   \n",
      "7         573     Story  84264   \n",
      "8         573     Story  85858   \n",
      "9         573     Story  85191   \n",
      "10        573     Story  84460   \n",
      "11        573     Story  83551   \n",
      "12        573     Story  83550   \n",
      "13        573     Story  81736   \n",
      "14        573       Bug  85499   \n",
      "15        573  Sub-Task  85959   \n",
      "16        573     Story  85872   \n",
      "17        573     Story  85507   \n",
      "18        573     Story  85506   \n",
      "19        573  Sub-Task  85505   \n",
      "20        573       Bug  85474   \n",
      "21        573     Story  85473   \n",
      "22        573  Sub-Task  85462   \n",
      "23        573     Story  85299   \n",
      "24        573     Story  85210   \n",
      "25        573     Story  82467   \n",
      "\n",
      "                                              summary  \\\n",
      "0   Sarek v3 randomly skips some samples from the ...   \n",
      "1      Support \"required tests\" in the input manifest   \n",
      "2   [SPIKE] Determine default behavior for executi...   \n",
      "3   As an output, return the input manifest but wi...   \n",
      "4                 Explore performing MVP file staging   \n",
      "5              Implement basic Nextflow Tower service   \n",
      "6   Configure secrets  for Airflow in GitHub Codes...   \n",
      "7                                  Explore Tower Wave   \n",
      "8                  Update nf-agora to use CLI command   \n",
      "9   Grant iAtlas NF tower access to UNC collaborators   \n",
      "10                Adapt `nf-cwl-wrap` to run on Tower   \n",
      "11                     Fix dependabot security alerts   \n",
      "12                  Create pipenv lock file for agora   \n",
      "13   Create CLI tool for agora-data-tools using typer   \n",
      "14          GENIE BPC R Shiny App keeps disconnecting   \n",
      "15  Update pilot data bucket to have the specs for...   \n",
      "16  [SPIKE] Determine production pipeline testing ...   \n",
      "17  RECOVER: Define and replicate production infra...   \n",
      "18  Modify Dev pre-ETL bucket (pilot data) to link...   \n",
      "19                   Create production pre-ETL bucket   \n",
      "20  Some parquet exports appear to be disabled for...   \n",
      "21  RECOVER: Make sure dev intermediate bucket and...   \n",
      "22  Set up parquet datasets for STS access in dev ...   \n",
      "23  Clean up namespaced cloudformation stacks and ...   \n",
      "24  Launch all stacks to production RECOVER AWS ac...   \n",
      "25  ADT Setup: Package versions need to be updated...   \n",
      "\n",
      "                                          description              status  \\\n",
      "0   As I was working on [https://sagebionetworks.j...         In Progress   \n",
      "1   Adam was asking about why the validation resul...  Waiting for Review   \n",
      "2   Feedback from Adam: “what are skipped tests?” ...                Open   \n",
      "3   As a DCQC user, I would like to know where the...                Open   \n",
      "4   Explore performing “lazy” file staging so that...                Open   \n",
      "5   Now that we have base classes from [https://sa...         In Progress   \n",
      "6   Thanks to [https://sagebionetworks.jira.com/br...                Open   \n",
      "7   Explore the new Tower wave on the tower dev ac...  Waiting for Review   \n",
      "8   With the implementation of the {{agora-data-to...              Closed   \n",
      "9   Add external collaborators for iAtlas to the i...  Waiting for Review   \n",
      "10  While working on [https://sagebionetworks.jira...         In Progress   \n",
      "11                     Fix dependabot security alerts              Closed   \n",
      "12  Jess would like dependabot security updates to...              Closed   \n",
      "13  Create CLI for agora-data-tools so that you do...              Closed   \n",
      "14  *Requestor*: Mike (AACR) per slack on 21MAR202...              Closed   \n",
      "15  Update develop/s3-pilot-data.yaml config to mi...                Open   \n",
      "16  Testing cannot take place in dev because the d...                Open   \n",
      "17  Make sure the files in {{prod}} stack mirror t...                Open   \n",
      "18  The dev pre-ETL bucket currently exists but it...                Open   \n",
      "19                   Create production pre-Etl bucket                Open   \n",
      "20  Digital health has noticed a recent dropoff in...  Waiting for Review   \n",
      "21  The cloud formation templates have to be updat...                Open   \n",
      "22  This should mirror [https://sagebionetworks.ji...                Open   \n",
      "23  This should delete namespaced cloudformation s...                Open   \n",
      "24  We decided that we would focus on the develop ...                Open   \n",
      "25  I tried to do a fresh install of {{agora-data-...              Closed   \n",
      "\n",
      "          assignee                        sprint target_start due_date  \n",
      "0     Bruno Grande  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "1     Bruno Grande  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "2     Bruno Grande  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "3   Brad Macdonald  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "4     Bruno Grande  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "5        rixing.xu  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "6     Bruno Grande  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "7   Brad Macdonald  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "8   Brad Macdonald  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "9   Brad Macdonald  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "10  Brad Macdonald  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "11  Brad Macdonald  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "12  Brad Macdonald  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "13  Brad Macdonald  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "14       Thomas Yu  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "15       rixing.xu  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "16     Phil Snyder  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "17       rixing.xu  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "18     Phil Snyder  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "19       rixing.xu  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "20     Phil Snyder  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "21       rixing.xu  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "22     Phil Snyder  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "23     Phil Snyder  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "24       rixing.xu  DPE 2023-03-27 to 2023-04-10         None     None  \n",
      "25  Brad Macdonald  DPE 2023-03-27 to 2023-04-10         None     None  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(jira_issues_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jira",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
